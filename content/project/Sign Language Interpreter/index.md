---
title: Sign Language Interpreter
summary: This project uses deep learning and time-series analysis to recognize sign language from continuous video data, employing a GCN model with sliding window techniques for improved sign segmentation and classification.
tags:
  - Computer Vision
date: '2024-07-27T00:00:00Z'

# Optional external URL for project (replaces project detail page).
external_link: ''

image:
  caption: ""
  focal_point: Smart

links:
  # - icon: github
  #   icon_pack: fab
  #   name: Follow
  #   url: https://github.com/Yasien99/GI-Tract-Image-Segmentation
url_code: 'https://github.com/Al-ameen007/Sign-Language-Interpreter'
url_pdf: ''
url_slides: ''
url_video: ''

# Slides (optional).
#   Associate this project with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides = "example-slides"` references `content/slides/example-slides.md`.
#   Otherwise, set `slides = ""`.
# slides: example
---
# Sign-Language-Interpreter
This project develops a system for recognizing sign language from videos by using time-series analysis and advanced machine learning techniques. It processes video data by extracting frames, detecting landmarks like facial or hand keypoints, and preparing the data for model training. A Graph Convolutional Network (GCN) is implemented to learn temporal dependencies and accurately classify signs. The project also employs sliding windows and change point detection to handle continuous signing, improving the modelâ€™s ability to segment and recognize signs in real-time video streams.




